{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Virtex \n",
    "## End-to-End Pose Recognition\n",
    "\n",
    "Virtex is an easy to use API for pose recognition, built on top of OpenPose, which lets you estimate and classify the poses. You can train on images having those poses or you can also train for poses in real time using the webcam. The classifier implements XG Boost Classifier to train and make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Link to Blog Post on Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started and Generating Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep things simple, let's just train our model to recognize standing, running and crouching. Before you start coding, make sure you are the directory of the repository to ensure we are on the same page. It is recommended to use jupyter notebook so that you can follow along easily.\n",
    "\n",
    "Firstly, import the necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from time import sleep\n",
    "from api import preprocess_data, train_classifier, cross_val, generate_data, predict\n",
    "from utils import combine_poses, save_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generate_data() function simplifies the data generation process with just a single line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capturing standing pose in 3 seconds\n"
     ]
    }
   ],
   "source": [
    "print('Capturing standing pose in 3 seconds')\n",
    "sleep(3)\n",
    "generate_data('realtime', pose='standing', save_to='./example/data/', save_as='standing.csv', nb_frames=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this function only generates data for a single pose at a time, we will run this function two more times for the remaining two poses i.e. crouch and running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capturing crouch pose in 3 seconds\n"
     ]
    }
   ],
   "source": [
    "print('Capturing crouch pose in 3 seconds')\n",
    "sleep(3)\n",
    "generate_data('realtime', pose='crouch', save_to='./example/data/', save_as='crouch.csv', nb_frames=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capturing running pose in 3 seconds\n"
     ]
    }
   ],
   "source": [
    "print('Capturing running pose in 3 seconds')\n",
    "sleep(3)\n",
    "generate_data('realtime', pose='running', save_to='./example/data/', save_as='running.csv', nb_frames=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and Preparing the Data\n",
    "As you have observed that each pose has its own csv file, so we need to combine the csv files into one dataset and prepare it for the classfier.\n",
    "The csv files can be combines easily using the combine_poses(*args) function from utils which accepts multiple file paths of the pose csv files as arguments and returns a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = combine_poses('./example/data/standing.csv','./example/data/crouch.csv','./example/data/running.csv')\n",
    "# Optionally you can write the dataframe object to a csv for future reference\n",
    "dataset.to_csv('./example/data/pose.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the dataset as a dataframe, we can directly send it for preprocessing using the preprocess_data() function which encodes the labels and prepares the X and Y arrays. It takes a dataframe as argument and returns two arrays i.e. X_train and y_labels and one dictionary containing a mapping from encoded integers to class labels so that we can use it display the name of the pose instead of the integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_labels, classes = preprocess_data(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "Virtex has includes an XG Boost Classifier by default and the train_classifier() function makes it super easy to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = train_classifier(x_train, y_labels, save_as='pose', save_to='./example/classifiers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the cross_val() function to get the mean accuracy and the standard deviation. It takes the model and the x_train and y_labels as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9677777777777777 0.016063146994223287\n"
     ]
    }
   ],
   "source": [
    "acc_mean, acc_std = cross_val(classifier,x_train,y_labels)\n",
    "print(acc_mean,acc_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to save the classes dictionary as it will be useful during prediction\n",
    "save_obj(classes, './example/classifiers/pose.cls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "We are now ready to test out our model and make predictions. Just use the predict() function to make the predictions. Run the following line of code with the appropriate parameters and voila you have built a simple pose recognition program in more or less 10 lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(mode='realtime',classifier='./example/classifiers/pose.xgbc', cls_dict='./example/classifiers/pose.cls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
